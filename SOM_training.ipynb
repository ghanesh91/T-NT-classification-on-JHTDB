{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOM training script\n",
    "Perform SOM training on JHTDB's transitional turbulent boundary layer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import h5py\n",
    "import time as tt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import filters\n",
    "import skimage.morphology as morphology\n",
    "from skimage.morphology import square\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import cm\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database domain size and number of grid points\n",
    "x_min =   30.2185\n",
    "x_max = 1000.0650\n",
    "y_min =    0.0036\n",
    "y_max =   26.4880\n",
    "z_min =    0.0000\n",
    "z_max =  240.0000\n",
    "d99i  =    0.9648\n",
    "d99f  =   15.0433\n",
    "\n",
    "nx = 3320\n",
    "ny =  224\n",
    "nz = 2048\n",
    "\n",
    "# Database time duration\n",
    "Ti = 0\n",
    "Tf = Ti + 1175\n",
    "dt = 0.25\n",
    "\n",
    "# Create surface\n",
    "nix = round(nx / 8)\n",
    "niz = round(nz / 8)\n",
    "niy = round(ny / 50)\n",
    "x = np.linspace(x_min, x_max, nix)\n",
    "z = np.linspace(z_min, z_max, niz)\n",
    "y = np.linspace(y_min, y_max, niy); \n",
    "\n",
    "[X,Y,Z]=np.meshgrid(x,y,z)\n",
    "print(niz,nix,niy,nix*niy*niz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read velocity and velocity gradient input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=sio.loadmat('data_t0.mat');\n",
    "\n",
    "u1=np.zeros((nix,niz,niy), np.float64);\n",
    "u2=np.zeros((nix,niz,niy), np.float64);\n",
    "u3=np.zeros((nix,niz,niy), np.float64);\n",
    "up1=np.zeros((nix,niz,niy), np.float64);\n",
    "up2=np.zeros((nix,niz,niy), np.float64);\n",
    "up3=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj1=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj2=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj3=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj4=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj5=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj6=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj7=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj8=np.zeros((nix,niz,niy), np.float64);\n",
    "duidxj9=np.zeros((nix,niz,niy), np.float64);\n",
    "\n",
    "u1[:,:,:]=data['ui'][:,:,:,0];\n",
    "u2[:,:,:]=data['ui'][:,:,:,1];\n",
    "u3[:,:,:]=data['ui'][:,:,:,2];\n",
    "duidxj1[:,:,:]=data['duidxj'][:,:,:,0];\n",
    "duidxj2[:,:,:]=data['duidxj'][:,:,:,1];\n",
    "duidxj3[:,:,:]=data['duidxj'][:,:,:,2];\n",
    "duidxj4[:,:,:]=data['duidxj'][:,:,:,3];\n",
    "duidxj5[:,:,:]=data['duidxj'][:,:,:,4];\n",
    "duidxj6[:,:,:]=data['duidxj'][:,:,:,5];\n",
    "duidxj7[:,:,:]=data['duidxj'][:,:,:,6];\n",
    "duidxj8[:,:,:]=data['duidxj'][:,:,:,7];\n",
    "duidxj9[:,:,:]=data['duidxj'][:,:,:,8];\n",
    "\n",
    "\n",
    "u1m=np.mean(u1,axis=1).reshape((nix,niy))\n",
    "u2m=np.mean(u2,axis=1).reshape((nix,niy))\n",
    "u3m=np.mean(u3,axis=1).reshape((nix,niy))\n",
    "for k in range(niz):\n",
    "    up1[:,k,:]=u1[:,k,:]-u1m;\n",
    "    up2[:,k,:]=u2[:,k,:]-u2m;\n",
    "    up3[:,k,:]=u3[:,k,:]-u3m;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize up1 contour\n",
    "yloc=0\n",
    "plt.contourf(x,z,np.transpose(up1[:,:,yloc]),22)\n",
    "plt.set_cmap(\"summer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input vector definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = np.zeros((nix*niz*niy, 16), np.float32)      # Size of input vector (u,v,w,up,vp, du/dxyz,dv/dxyz, dw/dxyz, x,y)\n",
    "std_vector = np.zeros((1, 16), np.float32)      # Size of input vector (u,v,w,up,vp, du/dxyz,dv/dxyz, dw/dxyz, x,y)\n",
    "input_vector[:,0]=np.abs(u1[:,:,:]).flatten()               # u\n",
    "input_vector[:,1]=np.abs(u2[:,:,:]).flatten()               # v\n",
    "input_vector[:,2]=np.abs(u3[:,:,:]).flatten()               # w\n",
    "input_vector[:,3]=np.abs(up1[:,:,:]).flatten()              # up\n",
    "input_vector[:,4]=np.abs(up2[:,:,:]).flatten()              # vp\n",
    "input_vector[:,5]=np.abs(duidxj1[:,:,:]).flatten()            # dudx\n",
    "input_vector[:,6]=np.abs(duidxj2[:,:,:]).flatten()            # dudy\n",
    "input_vector[:,7]=np.abs(duidxj3[:,:,:]).flatten()            # dudz\n",
    "input_vector[:,8]=np.abs(duidxj4[:,:,:]).flatten()            # dvdx\n",
    "input_vector[:,9]=np.abs(duidxj5[:,:,:]).flatten()            # dvdy\n",
    "input_vector[:,10]=np.abs(duidxj6[:,:,:]).flatten()           # dvdz\n",
    "input_vector[:,11]=np.abs(duidxj7[:,:,:]).flatten()           # dwdx\n",
    "input_vector[:,12]=np.abs(duidxj8[:,:,:]).flatten()           # dwdy\n",
    "input_vector[:,13]=np.abs(duidxj9[:,:,:]).flatten()           # dwdz\n",
    "input_vector[:,14]=np.abs(X[:,:,:]).flatten()              # x\n",
    "input_vector[:,15]=np.abs(Y[:,:,:]).flatten()              # y\n",
    "\n",
    "#Standard deviation and coefficients from Zhao et al 2019\n",
    "std_vector_zhao=np.array([[0.1312,0.0229,0.0264,0.04,0.0229,0.0243,0.1595,0.0626,\n",
    "               0.0246,0.0296,0.0385,0.0270,0.0536,0.0306,286.6778,8.2739]])\n",
    "coeffs_zhao=np.array([0.19, -0.15, -0.16, -0.16, -0.16, -0.17, -0.10, -0.15,\n",
    "                -0.15, -0.17, -0.16, -0.17, -0.16, -0.17, -0.08, 0.15])\n",
    "for i in range(input_vector.shape[1]):\n",
    "    print(i)\n",
    "    std_vector[0,i]=np.std(input_vector[:,i])\n",
    "    input_vector[:,i]=input_vector[:,i]/std_vector[0,i]  # Normalize by standard devition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if varaiance of input data is 1\n",
    "for i in range(input_vector.shape[1]):\n",
    "    print('variance',np.var(input_vector[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data using Kmeans clustering (SOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode data as T or NT using KMeans clustering (Zhao et al, 2018) \n",
    "start = tt.time()\n",
    "print('Machine learning training...')\n",
    "kmeans = KMeans(n_clusters=2).fit(input_vector)\n",
    "end = tt.time()\n",
    "print('   '+str(end - start)+' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding co-efficients\n",
    "#mask=kmeans.labels_.reshape((niz,nix,niy))\n",
    "\n",
    "a=kmeans.cluster_centers_[0]\n",
    "b=kmeans.cluster_centers_[1]\n",
    "c=np.zeros(a.shape[0])\n",
    "coeffs=np.zeros(a.shape[0])\n",
    "\n",
    "for i in range(a.shape[0]):\n",
    "    c[i]=0.5*(a[i]+b[i])\n",
    "B=0\n",
    "for i in range(c.shape[0]):\n",
    "    B=B-c[i]*(b[i]-a[i])\n",
    "    \n",
    "#co-efficients\n",
    "for i in range(c.shape[0]):\n",
    "    coeffs[i]=(b[i]-a[i])/B\n",
    "print(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare weights with Zhao et al, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(coeffs)\n",
    "print(coeffs_zhao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform T-NT classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-NT classification of training data\n",
    "mask=np.zeros((nix*niz*niy),np.int32)\n",
    "y_true=[]\n",
    "for i in range(nix*niz*niy):\n",
    "    p=1\n",
    "    for k in range(16):\n",
    "        p=p+coeffs[k]*input_vector[i,k]\n",
    "    if p<0:\n",
    "        mask[i]=1#turbulent\n",
    "        y_true.append(\"T\")\n",
    "    elif p>0:\n",
    "        mask[i]=0#laminar\n",
    "        y_true.append(\"NT\")\n",
    "        \n",
    "mask = mask.reshape((nix,niz,niy))\n",
    "#sio.savemat('mask_t0_SOM.mat',{'mask_t0_SOM':mask,'coeffs_t0_SOM':coeffs,'x':x,'y':y,'z':z})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize \\sqrt{v'^2+w'^2} with T-NT interface\n",
    "yloc=1\n",
    "#plot sqrt(v^2+w^2)\n",
    "plt.contourf(x,z,np.sqrt(u2[:,:,yloc]**2+u3[:,:,yloc]**2).transpose(),22)\n",
    "plt.set_cmap(\"summer\")\n",
    "#plot T/NT interface\n",
    "plt.contour(x,z,mask[:,:,yloc].transpose(),1,colors='black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
